# ============================================================
# Kalshi Market Data Collector — Configuration
# ============================================================

kalshi:
  # API credentials: set via env vars KALSHI_API_KEY_ID and KALSHI_PRIVATE_KEY_PATH
  # (see .env.example in this directory)
  private_key_path: "/home/kaitores/.kalshi/kalshi_api_key.txt"

  base_url: "https://api.elections.kalshi.com/trade-api/v2"
  ws_url:   "wss://api.elections.kalshi.com/trade-api/ws/v2"

# Series prefixes to track (uppercase).  At startup the collector queries the
# Kalshi API for currently-open events in each series and picks the active one
# automatically — no manual date updates needed.
# Example: KXHIGHCHI  →  auto-resolves to KXHIGHCHI-26FEB18 (or whatever is open today)
event_series:
  - "KXHIGHCHI"
  - "KXHIGHNY"

# Optional: pin specific dated event tickers here (legacy / override).
# events:
#   - "KXHIGHCHI-26FEB18"

# ----------------------------------------------------------
# Snapshot collection
# ----------------------------------------------------------
collection:
  # Baseline: snapshot every N seconds regardless of price activity.
  interval_seconds: 60

  # Spike detection: snapshot immediately when any contract's yes_bid, yes_ask,
  # or last_price moves by ≥ threshold cents since the *last snapshot*.
  # Compared against the last-snapshotted price (not the last WS message),
  # so cumulative moves during cooldown are never missed.
  spike_threshold_cents: 3

  # Min seconds between event-driven snapshots (prevents burst writes when
  # multiple contracts spike simultaneously or prices oscillate).
  spike_cooldown_seconds: 2

  # Max orderbook depth saved per side (yes/no) per contract per snapshot.
  # Levels are kept by best price (highest bids first for yes, no sides).
  # Set to 0 to save all levels.
  max_orderbook_depth: 5

  # Delta compression: write full orderbook baselines every N snapshots,
  # and only changed/removed levels in between. Saves ~80-90% of OB rows.
  # Set to 1 to disable (every snapshot is a baseline, i.e. original behavior).
  baseline_every_n_snapshots: 60

# ----------------------------------------------------------
# Storage
# ----------------------------------------------------------
storage:
  # Relative to this config file's directory.
  data_dir: "data"

  # How often to flush in-memory buffers to parquet (seconds).
  flush_interval_seconds: 300
